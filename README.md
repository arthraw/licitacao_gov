# ğŸ“Š Pipeline de Dados de LicitaÃ§Ãµes Governamentais

Pipeline completo de ingestÃ£o, processamento e anÃ¡lise de dados de licitaÃ§Ãµes do governo brasileiro, utilizando arquitetura moderna de Data Lake com camadas medallion (Bronze, Silver, Gold).

## ğŸ¯ Objetivo do Projeto

Automatizar a coleta, processamento e disponibilizaÃ§Ã£o de dados pÃºblicos de licitaÃ§Ãµes governamentais, permitindo anÃ¡lises e insights sobre processos licitatÃ³rios no Brasil.

## ğŸ—ï¸ Arquitetura
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE DADOS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   Airflow    â”‚â”€â”€â”€â”€â”€â–¶â”‚   Airbyte    â”‚                     â”‚
â”‚  â”‚(OrquestraÃ§Ã£o)â”‚      â”‚  (IngestÃ£o)  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                               â”‚                             â”‚
â”‚                               â–¼                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                    â”‚  Azure Synapse      â”‚                  â”‚
â”‚                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                  â”‚
â”‚                    â”‚  â”‚  Spark Pool   â”‚  â”‚                  â”‚
â”‚                    â”‚  â”‚  (Processing) â”‚  â”‚                  â”‚
â”‚                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                               â”‚                             â”‚
â”‚                               â–¼                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚              â”‚   ADLS Gen2 (Data Lake)        â”‚             â”‚
â”‚              â”‚                                â”‚             â”‚
â”‚              â”‚  ğŸ“ Transient (staging)        â”‚             â”‚
â”‚              â”‚  ğŸ“ Bronze (raw)               â”‚             â”‚
â”‚              â”‚  ğŸ“ Silver (cleaned)           â”‚             â”‚
â”‚              â”‚  ğŸ“ Gold (aggregated)          â”‚             â”‚
â”‚              â”‚  ğŸ“ Archive (historical)       â”‚             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Stack TecnolÃ³gica

### OrquestraÃ§Ã£o & Workflow
- **Apache Airflow** - OrquestraÃ§Ã£o de pipelines e scheduling
- **Airbyte** - Plataforma de ingestÃ£o de dados (ELT)

### Processamento & Armazenamento
- **Azure Synapse Analytics** - Data warehouse e processamento distribuÃ­do
- **Apache Spark** (via Synapse) - Processamento big data
- **Delta Lake** - Camada de armazenamento ACID
- **Azure Data Lake Storage Gen2** - Data lake escalÃ¡vel

### Infraestrutura como CÃ³digo
- **Terraform** - Provisionamento de infraestrutura na Azure
- **Azure CLI** - AutomaÃ§Ã£o e configuraÃ§Ã£o

### Linguagens & Ferramentas
- **Python** - Scripts e transformaÃ§Ãµes
- **PySpark** - Processamento distribuÃ­do de dados
- **SQL** - Queries e transformaÃ§Ãµes

## ğŸ“ Estrutura do Projeto

```
licitacao_gov/
â”‚
â”œâ”€â”€ airflow/                    # ConfiguraÃ§Ã£o do Airflow
â”‚   â”œâ”€â”€ dags/                   # DAGs de orquestraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ licitacoes_dag.py  # Pipeline principal
â”‚
â”œâ”€â”€ airbyte/                    # ConfiguraÃ§Ã£o do Airbyte
â”‚   â”œâ”€â”€ sources/                # DefiniÃ§Ãµes de fontes de dados
â”‚
â”œâ”€â”€ src/                    # Fonte do cÃ³digo
â”‚   â”œâ”€â”€ notebooks/              # Notebooks PySpark
â”‚   â”‚   â”œâ”€â”€ bronze_to_silver.ipynb
â”‚   â”‚   â””â”€â”€ silver_to_gold.ipynb
â”‚
â”œâ”€â”€ infra/                      # Infraestrutura como CÃ³digo
â”‚   â”œâ”€â”€ main.tf                 # Recursos principais
â”‚   â”œâ”€â”€ variables.tf            # VariÃ¡veis
â”‚   â”œâ”€â”€ outputs.tf              # Outputs
â”‚   â””â”€â”€ README.md               # ğŸ“– [DocumentaÃ§Ã£o de Infra](infra/README.md)
â”‚
â”œâ”€â”€ scripts/                    # Scripts auxiliares
â”‚   â”œâ”€â”€ setup.sh                # Setup inicial
â”‚   â””â”€â”€ deploy.sh               # Deploy automatizado
â”‚
â”œâ”€â”€ docs/                       # Arquivos para doc
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos

- **Azure Subscription** ativa
- **Terraform** >= 1.0
- **Azure CLI** autenticado
- **Docker** & **Docker Compose**
- **Python** >= 3.9

### 1ï¸âƒ£ Provisionar Infraestrutura

```bash
cd infra/

# Configurar variÃ¡veis
cp terraform.tfvars.example terraform.tfvars
# Edite terraform.tfvars com suas configuraÃ§Ãµes

# Provisionar recursos Azure
terraform init
terraform plan
terraform apply

# Salvar credenciais do Service Principal
terraform output -raw airflow_client_secret > ../credentials.txt
```

ğŸ“– **Detalhes**: Veja [infra/README.md](infra/README.md) para documentaÃ§Ã£o completa da infraestrutura.

### 2ï¸âƒ£ Configurar Airflow

```bash
# Inicializar projeto Astro
astro dev init

# Subir o Airflow localmente
astro dev start

# Acessar UI
# http://localhost:8080
# UsuÃ¡rio: admin / Senha: admin

# Configurar conexÃ£o Azure Synapse, adls e airbyte

```

### 3ï¸âƒ£ Configurar Airbyte

```bash
sudo abctl local install

# Acessar UI
# http://localhost:8000
# UsuÃ¡rio: airbyte / Senha: *pega utilizando o comando abaixo:*
sudo abctl local credentials
```

### Configurar source e destination

Crie uma nova source de API pela aba BUILDER na UI, e importe o yaml que esta em airbyte/sources/licitacoes_gov_br.yaml

Apos isso configure uma connection com a destination Azure Blob Storage


### 4ï¸âƒ£ Executar Pipeline

**Via Airflow UI, ative e execute a DAG 'licitacoes_dag'**


## ğŸ“Š Camadas de Dados (Medallion Architecture)

### ğŸ¥‰ Bronze (Raw)
- Dados brutos ingeridos sem transformaÃ§Ã£o
- Formato: JSON/Parquet original
- RetenÃ§Ã£o: 90 dias

### ğŸ¥ˆ Silver (Cleaned)
- Dados limpos e normalizados
- ValidaÃ§Ãµes de qualidade aplicadas
- Formato: Delta Lake
- RetenÃ§Ã£o: 1 ano

### ğŸ¥‡ Gold (Aggregated)
- Dados agregados e otimizados para anÃ¡lise
- KPIs e mÃ©tricas de negÃ³cio
- Formato: Delta Lake / Tabela fÃ­sica
- RetenÃ§Ã£o: Indefinida

### ğŸ“¦ Transient
- Ãrea de staging temporÃ¡ria
- Dados intermediÃ¡rios durante processamento

### ğŸ—„ï¸ Archive
- Dados histÃ³ricos arquivados
- Conformidade e auditoria
- Armazenamento de longo prazo

## ğŸ”„ Fluxo de Dados

```
1. IngestÃ£o (Airbyte)
   â””â”€> API LicitaÃ§Ãµes â†’ Transient (JSON)

2. Raw Layer (Airflow â†’ Synapse)
   â””â”€> Transient â†’ Bronze (Parquet)

3. Archive (Airflow)
   â””â”€> Bronze â†’ Archive (histÃ³rico)

4. Cleaned Layer (Synapse Spark)
   â””â”€> Bronze â†’ Silver (Delta Lake)
        â”œâ”€ ValidaÃ§Ã£o de schema
        â”œâ”€ Limpeza de dados
        â”œâ”€ DeduplicaÃ§Ã£o
        â””â”€ NormalizaÃ§Ã£o

5. Aggregated Layer (Synapse Spark)
   â””â”€> Silver â†’ Gold (Delta Lake)
        â”œâ”€ AgregaÃ§Ãµes
        â”œâ”€ KPIs
        â””â”€ Tabelas dimensionais

```

## ğŸ” SeguranÃ§a & GovernanÃ§a

- âœ… **AutenticaÃ§Ã£o**: Service Principal com RBAC
- âœ… **Criptografia**: Em repouso (Storage) e em trÃ¢nsito (TLS)
- âœ… **Auditoria**: Logs centralizados no Azure Monitor
- âœ… **Firewall**: Regras de rede configuradas
- âœ… **Secrets**: Gerenciados via Terraform (sensitive outputs)
- âœ… **LGPD/GDPR**: Dados anonimizados quando necessÃ¡rio

## ğŸ“ˆ Monitoramento

- **Airflow UI**: Status de DAGs e tasks
- **Azure Monitor**: MÃ©tricas de recursos
- **Synapse Studio**: ExecuÃ§Ã£o de pipelines e queries

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ‘¥ Autor

- **Arthur Andrade** - [GitHub](https://github.com/arthraw)

## ğŸ“š DocumentaÃ§Ã£o Adicional

- ğŸ—ï¸ **[Infraestrutura (Terraform)](infra/README.md)** - Setup completo da infraestrutura Azure

---

<div align="center">
  <p>Feito com â¤ï¸ usando tecnologias open source e Azure</p>
  <p>â­ Se este projeto foi Ãºtil, considere dar uma estrela!</p>
</div>